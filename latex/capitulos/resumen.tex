
\chapter*{Resumen}

En los últimos años se ha extendido el uso de los \emph{word embeddings} para medir sesgos y estereotipos sociales en textos. Las métricas basadas en \emph{word embeddings} han demostrado su eficacia en la detección de una amplia variedad de sesgos pero carecen de transparencia e interpretabilidad. En esta tesis introducimos y analizamos una métrica alternativa basada en \emph{Pointwise Mutual Information} (PMI) para medir sesgos en textos. Mostramos que esta métrica, a diferencia de las métricas basadas en \emph{word embeddings}: (1) puede expresarse como una función de probabilidades condicionales, lo que proporciona una interpretación sencilla en términos de coocurrencias de palabras, y (2) permite estimar intervalos de confianza y la significación estadística de los resultados paramétricamente. Realizamos un conjunto de experimentos para comparar la métrica basada en PMI con las métricas basadas en \emph{word embeddings} en tres dimensiones: estimación de la variabilidad, correlación con el juicio humano e interpretabilidad. Los resultados sirven para ilustrar las ventajas del método basado en PMI, así como también la diferencia fundamental en el tipo de asocaciones semánticas que capturan. El código usado para realizar esta tesis está disponible en \url{https://github.com/ftvalentini/tesis-SesgoPMI}.

% A partir de un conjunto de experimentos, mostramos que, además de las ventajas en términos de interpretabilidad y fiabilidad de la inferencia estadística, el enfoque basado en PMI produce resultados similares a los de las métricas basadas en \emph{embeddings} a la hora de captar las diferencias de género del mundo real incrustadas en grandes corpus.

\vspace{1cm}

{\let\clearpage\relax\chapter*{Abstract}}

In recent years, the use of \emph{word embeddings}  to measure social biases and stereotypes in texts has become widespread. Metrics based on \emph{word embeddings}  have been shown to be effective in detecting a wide variety of biases but lack transparency and interpretability. In this thesis we introduce and analyse an alternative metric based on \emph{Pointwise Mutual Information} (PMI) to measure bias in texts. We show that this metric, unlike metrics based on \emph{word embeddings}: (1) can be expressed as a conditional probability function, which provides a simple interpretation in terms of word co-occurrences, and (2) allows estimating confidence intervals and the statistical significance of the results parametrically. We conducted a set of experiments to compare PMI-based metrics with metrics based on \emph{word embeddings} along three dimensions: variability estimation, correlation with human judgement, and interpretability. The results serve to illustrate the advantages of the PMI-based method, as well as the fundamental difference in the type of semantic associations they capture. The code used for this thesis is available at \url{https://github.com/ftvalentini/tesis-SesgoPMI}.
